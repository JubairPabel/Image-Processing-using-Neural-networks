{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.32941176, 0.7254902 , 0.62352941, 0.59215686,\n",
       "        0.23529412, 0.14117647, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.87058824, 0.99607843, 0.99607843, 0.99607843,\n",
       "        0.99607843, 0.94509804, 0.77647059, 0.77647059, 0.77647059,\n",
       "        0.77647059, 0.77647059, 0.77647059, 0.77647059, 0.77647059,\n",
       "        0.66666667, 0.20392157, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.2627451 , 0.44705882, 0.28235294, 0.44705882,\n",
       "        0.63921569, 0.89019608, 0.99607843, 0.88235294, 0.99607843,\n",
       "        0.99607843, 0.99607843, 0.98039216, 0.89803922, 0.99607843,\n",
       "        0.99607843, 0.54901961, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.06666667, 0.25882353, 0.05490196, 0.2627451 ,\n",
       "        0.2627451 , 0.2627451 , 0.23137255, 0.08235294, 0.9254902 ,\n",
       "        0.99607843, 0.41568627, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.3254902 , 0.99215686,\n",
       "        0.81960784, 0.07058824, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.08627451, 0.91372549, 1.        ,\n",
       "        0.3254902 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.50588235, 0.99607843, 0.93333333,\n",
       "        0.17254902, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.23137255, 0.97647059, 0.99607843, 0.24313725,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.52156863, 0.99607843, 0.73333333, 0.01960784,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.03529412, 0.80392157, 0.97254902, 0.22745098, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.49411765, 0.99607843, 0.71372549, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.29411765,\n",
       "        0.98431373, 0.94117647, 0.22352941, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.0745098 , 0.86666667,\n",
       "        0.99607843, 0.65098039, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.79607843, 0.99607843,\n",
       "        0.85882353, 0.1372549 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.14901961, 0.99607843, 0.99607843,\n",
       "        0.30196078, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.12156863, 0.87843137, 0.99607843, 0.45098039,\n",
       "        0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.52156863, 0.99607843, 0.99607843, 0.20392157,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.23921569, 0.94901961, 0.99607843, 0.99607843, 0.20392157,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.4745098 , 0.99607843, 0.99607843, 0.85882353, 0.15686275,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.4745098 , 0.99607843, 0.81176471, 0.07058824, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "len(X_train)\n",
    "\n",
    "X_train = X_train/255\n",
    "X_test =  X_test/255\n",
    "\n",
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f7aafed208>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.4876 - accuracy: 0.8776\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.3064 - accuracy: 0.9160\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.2853 - accuracy: 0.9212\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.2749 - accuracy: 0.9238\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.2675 - accuracy: 0.9263\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.2628 - accuracy: 0.9279\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.2586 - accuracy: 0.9286\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.2558 - accuracy: 0.9296\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.2527 - accuracy: 0.9302\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.2499 - accuracy: 0.9305\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f7ac07c8c8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_flatten = X_train.reshape(len(X_train),28*28)\n",
    "X_test_flatten = X_test.reshape(len(X_test),28*28)\n",
    "#creating the model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(10, input_shape = (784,),activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "model.compile( \n",
    "        optimizer='adam',\n",
    "        loss = 'sparse_categorical_crossentropy',\n",
    "        metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(X_train_flatten,y_train, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 32us/sample - loss: 0.2619 - accuracy: 0.9276\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.26188701437711714, 0.9276]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_flatten, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(X_test[2])\n",
    "\n",
    "y_pred = model.predict(X_test_flatten)\n",
    "y_pred[2]\n",
    "\n",
    "np.argmax(y_pred[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 10), dtype=int32, numpy=\n",
       "array([[ 965,    0,    0,    2,    0,    4,    6,    2,    1,    0],\n",
       "       [   0, 1118,    3,    2,    0,    1,    4,    2,    5,    0],\n",
       "       [   6,    9,  938,   15,    9,    4,   12,    9,   27,    3],\n",
       "       [   4,    0,   19,  925,    0,   21,    3,   12,   18,    8],\n",
       "       [   1,    2,    5,    0,  914,    0,   10,    4,    8,   38],\n",
       "       [  10,    3,    3,   36,   10,  778,   15,    7,   25,    5],\n",
       "       [  12,    3,    5,    1,    7,    9,  918,    2,    1,    0],\n",
       "       [   2,    7,   25,    5,    7,    1,    0,  946,    1,   34],\n",
       "       [  10,   13,    6,   25,    9,   32,   10,   10,  847,   12],\n",
       "       [  11,    8,    1,   12,   20,    6,    0,   20,    4,  927]])>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#showing the confusion matrix\n",
    "y_pred_labels = [np.argmax(i) for i in y_pred ]\n",
    "\n",
    "cm = tf.math.confusion_matrix(labels = y_test,predictions = y_pred_labels)\n",
    "cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.2963 - accuracy: 0.9177\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.1383 - accuracy: 0.9593\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.1000 - accuracy: 0.9707\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 0.0794 - accuracy: 0.9754\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 0.0635 - accuracy: 0.9805\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.0541 - accuracy: 0.9832\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 0.0446 - accuracy: 0.9865\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 0.0377 - accuracy: 0.9883\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 0.0332 - accuracy: 0.9899\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 0.0289 - accuracy: 0.9912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f7a646d348>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using multiple hidden layers\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(100, input_shape = (784,),activation = 'relu'),\n",
    "    keras.layers.Dense(10,activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "model.compile( \n",
    "        optimizer='adam',\n",
    "        loss = 'sparse_categorical_crossentropy',\n",
    "        metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(X_train_flatten,y_train, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 10), dtype=int32, numpy=\n",
       "array([[ 965,    0,    0,    2,    0,    4,    6,    2,    1,    0],\n",
       "       [   0, 1118,    3,    2,    0,    1,    4,    2,    5,    0],\n",
       "       [   6,    9,  938,   15,    9,    4,   12,    9,   27,    3],\n",
       "       [   4,    0,   19,  925,    0,   21,    3,   12,   18,    8],\n",
       "       [   1,    2,    5,    0,  914,    0,   10,    4,    8,   38],\n",
       "       [  10,    3,    3,   36,   10,  778,   15,    7,   25,    5],\n",
       "       [  12,    3,    5,    1,    7,    9,  918,    2,    1,    0],\n",
       "       [   2,    7,   25,    5,    7,    1,    0,  946,    1,   34],\n",
       "       [  10,   13,    6,   25,    9,   32,   10,   10,  847,   12],\n",
       "       [  11,    8,    1,   12,   20,    6,    0,   20,    4,  927]])>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = tf.math.confusion_matrix(labels = y_test,predictions = y_pred_labels)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.2883 - accuracy: 0.9194s - loss: 0.2956 - accuracy\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.1311 - accuracy: 0.9618\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 0.0914 - accuracy: 0.9725\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.0708 - accuracy: 0.9782\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.0567 - accuracy: 0.9828\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.0478 - accuracy: 0.9851\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0387 - accuracy: 0.9880\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 0.0333 - accuracy: 0.9900\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 0.0272 - accuracy: 0.9916\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.0234 - accuracy: 0.9925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f7a7804a48>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#using flatten of keras \n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28,28)),\n",
    "    keras.layers.Dense(100, input_shape = (784,),activation = 'relu'),\n",
    "    keras.layers.Dense(10,activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "model.compile( \n",
    "        optimizer='adam',\n",
    "        loss = 'sparse_categorical_crossentropy',\n",
    "        metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(X_train,y_train, epochs = 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
